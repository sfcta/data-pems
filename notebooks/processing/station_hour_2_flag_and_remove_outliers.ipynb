{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "historic-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# peak hour and peak period volumes for typical weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vertical-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, gzip, shutil\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "#import geopandas as gpd\n",
    "import numpy as np\n",
    "import holidays\n",
    "#from shapely.geometry import Point, LineString\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fleet-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDIR = r'Q:\\Model Projects\\101_280\\data\\pems'\n",
    "OUTDIR = r'Q:\\Model Projects\\101_280\\data\\pems'\n",
    "data_type = 'station_hour'\n",
    "district = 4\n",
    "ca_holidays = holidays.UnitedStates(state='CA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ranking-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir(base, year=2020, data_type='station_hour', district=4):\n",
    "    if data_type in ['station_hour','station_5min','station_meta']:\n",
    "        return os.path.join(base,'D{}_Data_{}\\{}'.format(district,year,data_type))\n",
    "    elif data_type == 'processed_station_hour':\n",
    "        return os.path.join(base,'pems','pems_station_hour_{}.h5'.format(year))\n",
    "    \n",
    "def get_columns(data_type, num_cols):\n",
    "    if data_type == 'station_meta':\n",
    "        columns = ['station','route','dir','district','county','city','state_postmile','abs_postmile','latitude','longitude',\n",
    "                   'length','type','lanes','name','user_id_1','user_id_2','user_id_3','user_id_4']\n",
    "    if data_type == 'station_hour':\n",
    "        columns = ['timestamp', 'station', 'district', 'route', 'dir', 'lane_type', 'station_length',\n",
    "                   'samples', 'obs_pct', 'total_flow', 'avg_occupancy', 'avg_speed',\n",
    "                   'delay_35','delay_40','delay_45','delay_50','delay_55','delay_60']\n",
    "        for i in range(0, int((num_cols - 18) / 3)):\n",
    "            columns += [f'lane_{i}_flow',\n",
    "                        f'lane_{i}_avg_occ',\n",
    "                        f'lane_{i}_avg_speed',\n",
    "                       ]\n",
    "    if data_type == 'station_5min':\n",
    "        columns = ['timestamp', 'station', 'district', 'route', 'dir', 'lane_type', 'station_length',\n",
    "                   'samples', 'obs_pct', 'total_flow', 'avg_occupancy', 'avg_speed']\n",
    "        for i in range(0, int((num_cols - 12) / 5)):\n",
    "            columns += [f'lane_{i}_samples',\n",
    "                        f'lane_{i}_flow',\n",
    "                        f'lane_{i}_avg_occ',\n",
    "                        f'lane_{i}_avg_speed',\n",
    "                        f'lane_{i}_avg_obs',\n",
    "                       ]\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "extended-demand",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = pd.read_csv(os.path.join(INDIR,'stable_locations.csv'), infer_datetime_format=True, parse_dates=['start_date','end_date'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "administrative-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations['start_date'] = locations['start_date'].map(lambda x: x.date())\n",
    "locations['end_date'] = locations['end_date'].map(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "international-scholarship",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold = 25\n",
    "dfs = []\n",
    "data_type = 'processed_station_hour'\n",
    "\n",
    "typical_weekday = True\n",
    "include_holidays = True\n",
    "sf_only = False\n",
    "continuous_only = False\n",
    "\n",
    "if sf_only:\n",
    "    locations = locations.loc[locations['county'].eq(75)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "spread-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_holidays:\n",
    "    m = pd.read_csv(os.path.join(INDIR,'with_holidays','station_flow_mean_std_2005_2022.csv'))\n",
    "    OUTDIR = r'Q:\\Model Projects\\101_280\\data\\pems\\with_holidays'\n",
    "else:\n",
    "    m = pd.read_csv(os.path.join(INDIR,'station_flow_mean_std_2005_2021.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5bcfc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>hour</th>\n",
       "      <th>era</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400001</td>\n",
       "      <td>0</td>\n",
       "      <td>covid-2020</td>\n",
       "      <td>314.226667</td>\n",
       "      <td>68.150980</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400001</td>\n",
       "      <td>0</td>\n",
       "      <td>covid-2021</td>\n",
       "      <td>353.551724</td>\n",
       "      <td>52.354786</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400001</td>\n",
       "      <td>0</td>\n",
       "      <td>pre-covid</td>\n",
       "      <td>465.872424</td>\n",
       "      <td>147.126910</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400001</td>\n",
       "      <td>1</td>\n",
       "      <td>covid-2020</td>\n",
       "      <td>234.693333</td>\n",
       "      <td>44.482907</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400001</td>\n",
       "      <td>1</td>\n",
       "      <td>covid-2021</td>\n",
       "      <td>268.120690</td>\n",
       "      <td>35.710374</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station  hour         era        mean         std     n\n",
       "0   400001     0  covid-2020  314.226667   68.150980    75\n",
       "1   400001     0  covid-2021  353.551724   52.354786    58\n",
       "2   400001     0   pre-covid  465.872424  147.126910  1019\n",
       "3   400001     1  covid-2020  234.693333   44.482907    75\n",
       "4   400001     1  covid-2021  268.120690   35.710374    58"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "english-dutch",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projects\\101_280\\data\\pems\\pems_station_hour_2005.h5\n",
      "removing stations with unknown location before: 1379145, after: 871514\n",
      "total_flow\n",
      "lane_0_flow\n",
      "lane_1_flow\n",
      "lane_2_flow\n",
      "lane_3_flow\n",
      "lane_4_flow\n",
      "lane_5_flow\n",
      "lane_6_flow\n",
      "lane_7_flow\n",
      "Projects\\101_280\\data\\pems\\pems_station_hour_2006.h5\n",
      "removing stations with unknown location before: 1390234, after: 861155\n",
      "total_flow\n",
      "lane_0_flow\n",
      "lane_1_flow\n",
      "lane_2_flow\n",
      "lane_3_flow\n",
      "lane_4_flow\n",
      "lane_5_flow\n",
      "lane_6_flow\n",
      "lane_7_flow\n",
      "Projects\\101_280\\data\\pems\\pems_station_hour_2007.h5\n",
      "removing stations with unknown location before: 1554620, after: 930782\n",
      "total_flow\n",
      "lane_0_flow\n",
      "lane_1_flow\n",
      "lane_2_flow\n",
      "lane_3_flow\n",
      "lane_4_flow\n",
      "lane_5_flow\n",
      "lane_6_flow\n",
      "lane_7_flow\n",
      "Projects\\101_280\\data\\pems\\pems_station_hour_2008.h5\n",
      "removing stations with unknown location before: 1703117, after: 992256\n",
      "total_flow\n",
      "lane_0_flow\n",
      "lane_1_flow\n",
      "lane_2_flow\n",
      "lane_3_flow\n",
      "lane_4_flow\n",
      "lane_5_flow\n",
      "lane_6_flow\n",
      "lane_7_flow\n",
      "Projects\\101_280\\data\\pems\\pems_station_hour_2009.h5\n",
      "removing stations with unknown location before: 1681720, after: 977793\n",
      "total_flow\n",
      "lane_0_flow\n",
      "lane_1_flow\n",
      "lane_2_flow\n",
      "lane_3_flow\n",
      "lane_4_flow\n",
      "lane_5_flow\n",
      "lane_6_flow\n",
      "lane_7_flow\n",
      "Projects\\101_280\\data\\pems\\pems_station_hour_2010.h5\n",
      "removing stations with unknown location before: 2121676, after: 1383790\n",
      "total_flow\n",
      "lane_0_flow\n",
      "lane_1_flow\n",
      "lane_2_flow\n",
      "lane_3_flow\n",
      "lane_4_flow\n",
      "lane_5_flow\n",
      "lane_6_flow\n",
      "lane_7_flow\n",
      "Projects\\101_280\\data\\pems\\pems_station_hour_2011.h5\n",
      "removing stations with unknown location before: 2067558, after: 1429346\n",
      "total_flow\n",
      "lane_0_flow\n",
      "lane_1_flow\n",
      "lane_2_flow\n",
      "lane_3_flow\n",
      "lane_4_flow\n",
      "lane_5_flow\n",
      "lane_6_flow\n",
      "lane_7_flow\n",
      "Projects\\101_280\\data\\pems\\pems_station_hour_2012.h5\n",
      "removing stations with unknown location before: 1786928, after: 1240011\n",
      "total_flow\n",
      "lane_0_flow\n",
      "lane_1_flow\n",
      "lane_2_flow\n",
      "lane_3_flow\n",
      "lane_4_flow\n",
      "lane_5_flow\n",
      "lane_6_flow\n",
      "lane_7_flow\n",
      "Projects\\101_280\\data\\pems\\pems_station_hour_2013.h5\n",
      "removing stations with unknown location before: 2541465, after: 1764134\n",
      "total_flow\n",
      "lane_0_flow\n",
      "lane_1_flow\n",
      "lane_2_flow\n",
      "lane_3_flow\n",
      "lane_4_flow\n",
      "lane_5_flow\n",
      "lane_6_flow\n",
      "lane_7_flow\n",
      "Projects\\101_280\\data\\pems\\pems_station_hour_2014.h5\n",
      "removing stations with unknown location before: 2789637, after: 1842750\n",
      "total_flow\n",
      "lane_0_flow\n",
      "lane_1_flow\n",
      "lane_2_flow\n",
      "lane_3_flow\n",
      "lane_4_flow\n",
      "lane_5_flow\n",
      "lane_6_flow\n",
      "lane_7_flow\n",
      "Projects\\101_280\\data\\pems\\pems_station_hour_2015.h5\n",
      "removing stations with unknown location before: 3050293, after: 1837367\n",
      "total_flow\n",
      "lane_0_flow\n",
      "lane_1_flow\n",
      "lane_2_flow\n",
      "lane_3_flow\n",
      "lane_4_flow\n",
      "lane_5_flow\n",
      "lane_6_flow\n",
      "lane_7_flow\n",
      "Projects\\101_280\\data\\pems\\pems_station_hour_2016.h5\n",
      "removing stations with unknown location before: 4172905, after: 2735320\n",
      "total_flow\n",
      "lane_0_flow\n",
      "lane_1_flow\n",
      "lane_2_flow\n",
      "lane_3_flow\n",
      "lane_4_flow\n",
      "lane_5_flow\n",
      "lane_6_flow\n",
      "lane_7_flow\n",
      "Projects\\101_280\\data\\pems\\pems_station_hour_2017.h5\n",
      "removing stations with unknown location before: 5021559, after: 3434832\n",
      "total_flow\n",
      "lane_0_flow\n",
      "lane_1_flow\n",
      "lane_2_flow\n",
      "lane_3_flow\n",
      "lane_4_flow\n",
      "lane_5_flow\n",
      "lane_6_flow\n",
      "lane_7_flow\n",
      "Projects\\101_280\\data\\pems\\pems_station_hour_2018.h5\n",
      "removing stations with unknown location before: 4865762, after: 3355487\n",
      "total_flow\n",
      "lane_0_flow\n",
      "lane_1_flow\n",
      "lane_2_flow\n",
      "lane_3_flow\n",
      "lane_4_flow\n",
      "lane_5_flow\n",
      "lane_6_flow\n",
      "lane_7_flow\n",
      "Projects\\101_280\\data\\pems\\pems_station_hour_2019.h5\n",
      "removing stations with unknown location before: 4921470, after: 3437811\n",
      "total_flow\n",
      "lane_0_flow\n",
      "lane_1_flow\n",
      "lane_2_flow\n",
      "lane_3_flow\n",
      "lane_4_flow\n",
      "lane_5_flow\n",
      "lane_6_flow\n",
      "lane_7_flow\n",
      "Projects\\101_280\\data\\pems\\pems_station_hour_2020.h5\n",
      "removing stations with unknown location before: 4406234, after: 3091534\n",
      "total_flow\n",
      "lane_0_flow\n",
      "lane_1_flow\n",
      "lane_2_flow\n",
      "lane_3_flow\n",
      "lane_4_flow\n",
      "lane_5_flow\n",
      "lane_6_flow\n",
      "lane_7_flow\n",
      "Projects\\101_280\\data\\pems\\pems_station_hour_2021.h5\n",
      "removing stations with unknown location before: 4028323, after: 2248968\n",
      "total_flow\n",
      "lane_0_flow\n",
      "lane_1_flow\n",
      "lane_2_flow\n",
      "lane_3_flow\n",
      "lane_4_flow\n",
      "lane_5_flow\n",
      "lane_6_flow\n",
      "lane_7_flow\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for year in np.arange(2005,2022):\n",
    "    f = os.path.join(INDIR,'pems_station_hour_{}.h5'.format(year))\n",
    "    print(f.split()[1])\n",
    "    df = pd.read_hdf(f)\n",
    "    \n",
    "    #groupby_cols = ['station','route','dir','type','county','city','start_name','end_name','is_complete','year','hour']\n",
    "    groupby_cols = ['station','route','dir','type','year','hour']\n",
    "    flow_cols = ['total_flow','lane_0_flow','lane_1_flow','lane_2_flow','lane_3_flow',\n",
    "                 'lane_4_flow','lane_5_flow','lane_6_flow','lane_7_flow']\n",
    "    agg_args = {c:['mean','std'] for c in flow_cols}\n",
    "    \n",
    "    if typical_weekday:\n",
    "        df = df.loc[df['month'].isin([3,4,5,9,10,11]) & df['day_of_week'].isin([1,2,3]) & ~df['is_holiday']]\n",
    "    else:\n",
    "        groupby_cols = groupby_cols[:-1] + ['month','day_of_week'] + groupby_cols[-1:]\n",
    "    \n",
    "    if include_holidays and not typical_weekday:\n",
    "        groupby_cols = groupby_cols[:-1] + ['is_holiday'] + groupby_cols[-1:]\n",
    "    else:\n",
    "        df = df.loc[~df['is_holiday']]\n",
    "        \n",
    "    df = df.loc[df['obs_pct'].ge(threshold)]\n",
    "    before = len(df)\n",
    "    df = pd.merge(locations, df, on='station', suffixes=['','_obs'])\n",
    "    df = df.loc[df['date'].between(df['start_date'], df['end_date'])]\n",
    "    after = len(df)\n",
    "    print('removing stations with unknown location before: {}, after: {}'.format(before, after))\n",
    "    \n",
    "    era = 'pre-covid'\n",
    "    if year >= 2020:\n",
    "        era = 'covid-{}'.format(year)\n",
    "        \n",
    "    df.insert(0,'era', era)\n",
    "    \n",
    "    df = pd.merge(df, m, on=['station','era','hour'])\n",
    "    \n",
    "    for c in flow_cols[1:]+flow_cols[:1]:\n",
    "        df.loc[df['total_flow'].eq(0),c] = np.nan\n",
    "        \n",
    "    df['devs'] = (df['total_flow'] - df['mean']).abs() / df['std']\n",
    "    \n",
    "    u = df.loc[df['devs'].lt(3),flow_cols]\n",
    "    \n",
    "    for c in flow_cols:\n",
    "        print(c)\n",
    "        df['orig_{}'.format(c.replace('_flow',''))] = df[c]\n",
    "        df[c] = np.nan\n",
    "    \n",
    "    df.update(u)\n",
    "    df = df.loc[df['devs'].lt(3)]\n",
    "    \n",
    "    #df.to_hdf(os.path.join(INDIR,'pems_station_hour_no_outliers_{}.h5'.format(year)), 'data', )\n",
    "    df.to_csv(os.path.join(OUTDIR,'pems_station_hour_no_outliers_{}.csv'.format(year)), index=False)\n",
    "    \n",
    "    df2 = df.groupby(groupby_cols, as_index=False).agg(agg_args)\n",
    "    dfs.append(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abstract-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "selected-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41c37295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = []\n",
    "for c1, c2 in df.columns:\n",
    "    sep = '_' if len(c2) > 0 else ''\n",
    "    c = '{}{}{}'.format(c1,sep,c2)\n",
    "    cols.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9555c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_cols = df.columns.tolist()\n",
    "df.columns=cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b49b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "i = 0\n",
    "if os.path.exists(os.path.join(OUTDIR,'pems_cleaned_2005_2022.csv')):\n",
    "    while True:\n",
    "        f = os.path.join(OUTDIR,'pems_cleaned_2005_2022_v{}.csv'.format(i))\n",
    "        if not os.path.exists(f):\n",
    "            shutil.copy(os.path.join(OUTDIR,'pems_cleaned_2005_2022.csv'),f)\n",
    "            break\n",
    "        i += 1\n",
    "df.to_csv(os.path.join(OUTDIR,'pems_cleaned_2005_2022.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
